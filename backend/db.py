# backend/db.py
from __future__ import annotations
from __future__ import annotations
import os, ssl, json, base64, asyncio
from datetime import datetime, timezone
from typing import Any, Dict, Optional, List

try:
    import asyncpg  # type: ignore
except Exception:
    asyncpg = None  # type: ignore


# --- Config ------------------------------------------------------------------

DB_CONNECT_TIMEOUT_SEC: float = float(os.getenv("DB_CONNECT_TIMEOUT_SEC", "10"))
MIGRATIONS_LOCK_KEY: int = int(os.getenv("MIGRATIONS_LOCK_KEY", "2147483601"))

_POOL: Optional["asyncpg.Pool"] = None
_LOCK: "asyncio.Lock" = asyncio.Lock()


# --- DSN / SSL helpers -------------------------------------------------------

def _dsn() -> str:
    dsn = os.getenv("DATABASE_URL", "").strip()
    if not dsn:
        raise RuntimeError("DATABASE_URL is not set")
    return dsn

def _ssl_ctx() -> Optional[ssl.SSLContext]:
    if os.getenv("PGSSL_DISABLE"):
        return None
    need = "sslmode=require" in _dsn().lower() or bool(os.getenv("PGSSL_REQUIRE"))
    if not need:
        return None
    ctx = ssl.create_default_context()
    b64 = os.getenv("PG_CA_CERT_BASE64", "").strip()
    if b64:
        try:
            pem = base64.b64decode(b64).decode("utf-8", "ignore")
            ctx.load_verify_locations(cadata=pem)
        except Exception:
            pass
    return ctx


# --- Pool management ----------------------------------------------------------

async def connect_pool():
    global _POOL
    if _POOL is not None:
        return _POOL
    async with _LOCK:
        if _POOL is not None:
            return _POOL
        if asyncpg is None:
            raise RuntimeError("asyncpg not installed")
        _POOL = await asyncpg.create_pool(
            dsn=_dsn(),
            timeout=DB_CONNECT_TIMEOUT_SEC,
            command_timeout=DB_CONNECT_TIMEOUT_SEC,
            min_size=int(os.getenv("PG_POOL_MIN", "1")),
            max_size=int(os.getenv("PG_POOL_MAX", "5")),
            ssl=_ssl_ctx(),
        )
        await ensure_schema()
        return _POOL


# --- Health / migrations ------------------------------------------------------

async def db_health() -> Dict[str, Any]:
    try:
        pool = await connect_pool()
        async with pool.acquire() as conn:
            await conn.fetchval("select 1;")
        return {"ok": True, "mode": "verified"}
    except Exception as e:
        return {"ok": False, "mode": "degraded", "error": str(e)}

async def run_migrations_idempotent() -> None:
    pool = await connect_pool()
    async with pool.acquire() as conn:
        await conn.execute("select pg_advisory_lock($1);", MIGRATIONS_LOCK_KEY)
        try:
            await ensure_schema()
        finally:
            await conn.execute("select pg_advisory_unlock($1);", MIGRATIONS_LOCK_KEY)

async def ensure_schema() -> None:
    pool = await connect_pool()
    async with pool.acquire() as conn:
        # Findings table (signals generated by agents)
        await conn.execute("""
            create table if not exists findings(
                id bigserial primary key,
                ts_utc timestamptz not null default now(),
                agent text not null,
                symbol text not null,
                score double precision not null,
                label text not null,
                details jsonb not null default '{}'::jsonb
            );
            create index if not exists idx_findings_symbol_ts
              on findings(symbol, ts_utc desc);
        """)

        # Raw 1-minute bars
        await conn.execute("""
            create table if not exists bars_1m(
                symbol text not null,
                ts_utc timestamptz not null,
                o double precision not null,
                h double precision not null,
                l double precision not null,
                c double precision not null,
                v double precision not null,
                vwap double precision,
                trades integer,
                primary key (symbol, ts_utc)
            );
            -- Optional: fast lookups/scans by symbol & time
            create index if not exists idx_bars_1m_symbol_ts
              on bars_1m(symbol, ts_utc desc);
        """)

        # Per-minute derived features
        await conn.execute("""
            create table if not exists features_1m(
                symbol text not null,
                ts_utc timestamptz not null,
                mom_bps_1m double precision,
                mom_bps_5m double precision,
                mom_bps_15m double precision,
                px_vs_vwap_bps_1m double precision,
                px_vs_vwap_bps_5m double precision,
                px_vs_vwap_bps_15m double precision,
                rvol_1m double precision,
                atr_1m double precision,
                schema_version integer not null default 1,
                primary key (symbol, ts_utc)
            );
            create index if not exists idx_features_1m_symbol_ts
              on features_1m(symbol, ts_utc desc);
        """)

        # Forward returns (5-minute horizon)
        await conn.execute("""
            create table if not exists returns_5m(
                symbol  text not null,
                ts_utc  timestamptz not null,
                ret_5m  double precision not null,
                primary key (symbol, ts_utc)
            );
            create index if not exists idx_returns_5m_symbol_ts
              on returns_5m(symbol, ts_utc desc);
        """)

        # Forward returns (15-minute horizon)
        await conn.execute("""
            create table if not exists returns_15m(
                symbol  text not null,
                ts_utc  timestamptz not null,
                ret_15m double precision not null,
                primary key (symbol, ts_utc)
            );
            create index if not exists idx_returns_15m_symbol_ts
              on returns_15m(symbol, ts_utc desc);
        """)

# compatibility alias some branches use
ensure_schema_v2 = ensure_schema

# --- Heartbeat -----------------------------------------------------------------
HEARTBEATS: Dict[str, Dict[str, str]] = {}
async def heartbeat(name: str = "db", status: str = "ok") -> str:
    ts = datetime.now(timezone.utc).isoformat()
    HEARTBEATS[name] = {"status": status, "last_run": ts}
    return ts

# --- Utilities -----------------------------------------------------------------
def _to_jsonb(value: Any) -> str:
    try:
        import orjson  # type: ignore
        return orjson.dumps(value).decode("utf-8")
    except Exception:
        return json.dumps(value, separators=(",", ":"), default=str)

# --- Findings ------------------------------------------------------------------
async def insert_finding_row(row: Dict[str, Any]) -> None:
    pool = await connect_pool()
    details_json = _to_jsonb(row.get("details") or {})
    async with pool.acquire() as conn:
        await conn.execute(
            """
            insert into findings (agent, symbol, ts_utc, score, label, details)
            values ($1, $2, coalesce($3, now()), $4, $5, $6::jsonb)
            """,
            str(row.get("agent")),
            str(row.get("symbol")),
            row.get("ts_utc"),
            float(row.get("score", 0.0)),
            str(row.get("label", "")),
            details_json,
        )

async def fetch_recent_findings(symbol: Optional[str] = None, limit: int = 20) -> List[Dict[str, Any]]:
    pool = await connect_pool()
    async with pool.acquire() as conn:
        if symbol:
            rows = await conn.fetch(
                """select ts_utc, agent, symbol, score, label, details
                   from findings where symbol=$1
                   order by ts_utc desc limit $2""",
                symbol, int(limit)
            )
        else:
            rows = await conn.fetch(
                """select ts_utc, agent, symbol, score, label, details
                   from findings
                   order by ts_utc desc limit $1""",
                int(limit)
            )
    out = []
    for r in rows:
        out.append({
            "ts_utc": r["ts_utc"].isoformat() if r["ts_utc"] else None,
            "agent":  r["agent"],
            "symbol": r["symbol"],
            "score":  float(r["score"]),
            "label":  r["label"],
            "details": r["details"],  # asyncpg returns dict for jsonb
        })
    return out

# --- Feature snapshot (1m) -----------------------------------------------------
async def insert_features_1m(symbol: str, ts_utc, feat: Dict[str, Any]) -> None:
    pool = await connect_pool()
    cols = [
        "mom_bps_1m","mom_bps_5m","mom_bps_15m",
        "px_vs_vwap_bps_1m","px_vs_vwap_bps_5m","px_vs_vwap_bps_15m",
        "rvol_1m","atr_1m","schema_version"
    ]
    vals = [
        feat.get("mom_bps_1m"), feat.get("mom_bps_5m"), feat.get("mom_bps_15m"),
        feat.get("px_vs_vwap_bps_1m"), feat.get("px_vs_vwap_bps_5m"), feat.get("px_vs_vwap_bps_15m"),
        feat.get("rvol_1m"), feat.get("atr_1m"), int(feat.get("schema_version", 1)),
    ]
    placeholders = ",".join(f"${i}" for i in range(3, 3+len(vals)))
    set_clause   = ",".join(f"{c}=EXCLUDED.{c}" for c in cols)
    async with pool.acquire() as conn:
        await conn.execute(
            f"""insert into features_1m(symbol, ts_utc, {",".join(cols)})
                values($1,$2,{placeholders})
                on conflict(symbol, ts_utc) do update set {set_clause}""",
            symbol, ts_utc, *vals
        )

def _parse_cmd_tuples(cmd: str) -> int:
    """asyncpg returns e.g. 'INSERT 0 123'; return the trailing int if present."""
    try:
        return int(cmd.split()[-1])
    except Exception:
        return 0

async def refresh_return_views(
    symbol: str | None = None,
    lookback_minutes: int = 7 * 24 * 60,   # default 7d
    as_bps: bool = False,                  # if True, store basis points instead of fraction
) -> dict:
    """
    Upsert forward returns using 1m closes:
      ret_5m  = (close[t+5]  - close[t]) / close[t]
      ret_15m = (close[t+15] - close[t]) / close[t]
    Only rows with a defined forward close are written.
    """
    interval_str = f"{max(lookback_minutes, 0)} minutes"
    scale = 10000.0 if as_bps else 1.0

    pool = await connect_pool()
    async with pool.acquire() as conn:
        # 5-minute forward return
        cmd5 = await conn.execute(
            """
            with base as (
              select symbol, ts_utc, c,
                     lead(c, 5) over (partition by symbol order by ts_utc) as c_fwd
              from bars_1m
              where ts_utc >= now() - $1::interval
                and ($2::text is null or symbol = $2)
            )
            insert into returns_5m(symbol, ts_utc, ret_5m)
            select symbol, ts_utc, (($3 * (c_fwd - c)) / nullif(c, 0))
            from base
            where c_fwd is not null
            on conflict (symbol, ts_utc) do update
              set ret_5m = excluded.ret_5m;
            """,
            interval_str, symbol, scale,
        )

        # 15-minute forward return
        cmd15 = await conn.execute(
            """
            with base as (
              select symbol, ts_utc, c,
                     lead(c, 15) over (partition by symbol order by ts_utc) as c_fwd
              from bars_1m
              where ts_utc >= now() - $1::interval
                and ($2::text is null or symbol = $2)
            )
            insert into returns_15m(symbol, ts_utc, ret_15m)
            select symbol, ts_utc, (($3 * (c_fwd - c)) / nullif(c, 0))
            from base
            where c_fwd is not null
            on conflict (symbol, ts_utc) do update
              set ret_15m = excluded.ret_15m;
            """,
            interval_str, symbol, scale,
        )

    return {
        "upserted_5m": _parse_cmd_tuples(cmd5),
        "upserted_15m": _parse_cmd_tuples(cmd15),
        "units": "bps" if as_bps else "fraction",
        "symbol": symbol,
        "lookback_minutes": lookback_minutes,
    }

# --- Minimal posture/equity stubs used by simulate endpoints -------------------
_POSTURE: dict[str, dict] = {}
_EQUITY: dict[str, list[dict]] = {}

async def get_posture(symbol: str) -> dict:
    return _POSTURE.get(symbol, {"symbol": symbol, "posture": "NO_POSITION", "size": 0, "price": None})

async def set_posture(symbol: str, posture: str, size: float, price: Optional[float], reason: Optional[str] = None) -> None:
    _POSTURE[symbol] = {"symbol": symbol, "posture": posture, "size": float(size), "price": price, "reason": reason, "ts_utc": datetime.now(timezone.utc).isoformat()}

async def record_trade(symbol: str, side: str, qty: float, price: float) -> None:
    _EQUITY.setdefault(symbol, []).append({"ts_utc": datetime.now(timezone.utc).isoformat(), "side": side, "qty": float(qty), "price": float(price)})

async def equity_curve(symbol: str) -> dict:
    return {"symbol": symbol, "equity": _EQUITY.get(symbol, [])}
